# -*- coding: utf-8 -*-
"""LSTM Predicci√≥n de Ahorros 2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_fV5yjYVhvzL8xqFmnep0IRlV7qcj-aA
"""

!pip install openpyxl

import pandas as pd
from google.colab import files

# 1. Subir el archivo Excel
print("Por favor, sube el archivo Excel (Tablero de Ahorros):")
uploaded = files.upload()
file_name = list(uploaded.keys())[0]

# 2. Mostrar las hojas disponibles en el archivo
xls = pd.ExcelFile(file_name, engine='openpyxl')
print("\nüìÑ Hojas disponibles en el archivo:", xls.sheet_names)

# 3. Intentar cargar la hoja "BD" si existe, de lo contrario, usar la primera hoja
sheet_name = "BD" if "BD" in xls.sheet_names else xls.sheet_names[0]
df = pd.read_excel(xls, sheet_name=sheet_name)

print(f"\n‚úÖ Se carg√≥ la hoja: {sheet_name}")

# 4. Mostrar primeras filas y columnas disponibles
print("\nüìä Primeras filas del DataFrame (antes de limpieza):")
print(df.head())
print("\nüìå Columnas en el DataFrame:")
print(df.columns.tolist())

# 5. Eliminar filas donde 'Iniciativa' o 'Ahorro' sean NaN
if 'Iniciativa' in df.columns:
    df = df.dropna(subset=['Iniciativa'])
    print("\n‚úÖ Se eliminaron las filas donde 'Iniciativa' es NaN.")
if 'Ahorro' in df.columns:
    df = df.dropna(subset=['Ahorro'])
    print("\n‚úÖ Se eliminaron las filas donde 'Ahorro' es NaN.")

# 6. Revisar y corregir tipos de datos
if 'Meta Ahorro' in df.columns:
    df['Meta Ahorro'] = pd.to_numeric(df['Meta Ahorro'], errors='coerce')

if 'Ahorro Monetario' in df.columns:
    df['Ahorro Monetario'] = pd.to_numeric(df['Ahorro Monetario'], errors='coerce')

# 7. Procesar la columna 'Fecha del ahorro'
if 'Fecha del ahorro' not in df.columns:
    raise ValueError("El archivo no contiene la columna 'Fecha del ahorro'.")

print("\nValores √∫nicos en 'Fecha del ahorro' (original):")
print(df['Fecha del ahorro'].unique())

# Convertir 'Fecha del ahorro' a string, quitar espacios y luego a datetime
df['Fecha del ahorro'] = df['Fecha del ahorro'].astype(str).str.strip()
df['Fecha del ahorro'] = pd.to_datetime(df['Fecha del ahorro'], errors='coerce', infer_datetime_format=True)

print("\nValores √∫nicos en 'Fecha del ahorro' (tras conversi√≥n):")
print(df['Fecha del ahorro'].unique())

# Imputar NaT con la fecha m√≠nima encontrada (si existe al menos una fecha v√°lida)
if df['Fecha del ahorro'].notnull().any():
    fecha_min = df['Fecha del ahorro'].min()
    df['Fecha del ahorro'] = df['Fecha del ahorro'].fillna(fecha_min)
    print("\nValores √∫nicos en 'Fecha del ahorro' (despu√©s de imputar NaT):")
    print(df['Fecha del ahorro'].unique())
else:
    raise ValueError("No se encontr√≥ ninguna fecha v√°lida en 'Fecha del ahorro'.")

# 8. Ordenar el DataFrame por 'Fecha del ahorro' y calcular 'D√≠as desde inicio'
df = df.sort_values('Fecha del ahorro')
fecha_min = df['Fecha del ahorro'].min()
df['D√≠as desde inicio'] = (df['Fecha del ahorro'] - fecha_min).dt.days

# 9. Mostrar tanto las primeras 10 como las √∫ltimas 10 filas para verificar el c√°lculo
print("\nüìä Primeras 10 filas del DataFrame tras agregar 'D√≠as desde inicio':")
print(df[['Fecha del ahorro', 'D√≠as desde inicio']].head(10))
print("\nüìä √öltimas 10 filas del DataFrame tras agregar 'D√≠as desde inicio':")
print(df[['Fecha del ahorro', 'D√≠as desde inicio']].tail(10))

# 10. Eliminar columnas sin informaci√≥n √∫til
columnas_a_eliminar = ['Columna1', 'Columna2', 'Columna3', 'Columna4']
columnas_presentes = [col for col in columnas_a_eliminar if col in df.columns]
if columnas_presentes:
    df = df.drop(columns=columnas_presentes)
    print(f"\nüóëÔ∏è Se eliminaron las siguientes columnas vac√≠as: {columnas_presentes}")

# 11. Manejo de valores nulos en otras columnas
df['D√≠as desde inicio'].fillna(df['D√≠as desde inicio'].median(), inplace=True)

# 12. Resumen final del DataFrame
print("\nüìä Resumen final del DataFrame:")
print(df.info())
print("\nüìâ Valores nulos en cada columna:")
print(df.isnull().sum())

# 13. Guardar el DataFrame limpio en un nuevo archivo Excel
nombre_salida = "BD_Limpiada.xlsx"
df.to_excel(nombre_salida, index=False)
print(f"\n‚úÖ Archivo guardado como '{nombre_salida}'.")

!pip install tensorflow

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# ---------------------------
# 1. Cargar y Preprocesar Datos
df['Fecha del ahorro'] = pd.to_datetime(df['Fecha del ahorro'], errors='coerce')
df['D√≠as desde inicio'] = (df['Fecha del ahorro'] - df['Fecha del ahorro'].min()).dt.days
df['Ahorro_log'] = np.log1p(df['Ahorro'])

df['Meta Ahorro'] = pd.to_numeric(df['Meta Ahorro'], errors='coerce')
df['Meta Ahorro'].fillna(df['Meta Ahorro'].median(), inplace=True)

df = df.dropna(subset=['Ahorro', 'D√≠as desde inicio', 'Ahorro_log'])

features = ['Ahorro_log', 'D√≠as desde inicio', 'Meta Ahorro']
target = 'Ahorro_log'

X_df = df[features]
y_df = df[[target]]

# ---------------------------
# 2. Normalizaci√≥n
# ---------------------------
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_scaled = scaler_X.fit_transform(X_df)
y_scaled = scaler_y.fit_transform(y_df)

# ---------------------------
# 3. Crear Secuencias para LSTM
# ---------------------------
def create_sequences(X, y, time_steps=18):
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        Xs.append(X[i:i+time_steps])
        ys.append(y[i+time_steps])
    return np.array(Xs), np.array(ys)

time_steps = 18
X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)

# Dividir en train/test
split = int(len(X_seq) * 0.8)
X_train, X_test = X_seq[:split], X_seq[split:]
y_train, y_test = y_seq[:split], y_seq[split:]

# ---------------------------
# 4. Definir y entrenar el modelo LSTM
# ---------------------------
num_features = X_seq.shape[2]
model = Sequential([
    LSTM(64, activation='tanh', return_sequences=True, input_shape=(time_steps, num_features)),
    Dropout(0.3),
    LSTM(32, activation='tanh', return_sequences=False),
    Dense(40, activation='relu'),
    Dropout(0.3),
    Dense(1)  # Salida lineal
])

model.compile(optimizer='adam', loss='mse')

early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=6, min_lr=1e-5)

history = model.fit(
    X_train, y_train,
    epochs=50, batch_size=32,
    validation_split=0.20,
    callbacks=[early_stop, reduce_lr]
)

import matplotlib.pyplot as plt

# Graficar la p√©rdida en entrenamiento y validaci√≥n
plt.figure(figsize=(8,4))
plt.plot(history.history['loss'], label='Training Loss')
if 'val_loss' in history.history:
    plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('P√©rdida a lo largo de las √©pocas')
plt.xlabel('√âpocas')
plt.ylabel('P√©rdida (MSE)')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Get the original shape of X_test
original_shape = X_test.shape

# Reshape X_test to match the input shape expected by the model
# You need to provide the correct time_steps and num_features
X_test = X_test.reshape(original_shape[0], time_steps, num_features)

# Hacer predicciones
y_pred = model.predict(X_test)

# Desnormalizar las predicciones y los valores reales
y_pred_rescaled = scaler_y.inverse_transform(y_pred)
y_test_rescaled = scaler_y.inverse_transform(y_test.reshape(-1, 1)) # Reshape y_test for inverse_transform

# Calcular m√©tricas de evaluaci√≥n
mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)
r2 = r2_score(y_test_rescaled, y_pred_rescaled)

print(f'MSE: {mse:.4f}')
print(f'RMSE: {rmse:.4f}')
print(f'MAE: {mae:.4f}')
print(f'R¬≤: {r2:.4f}')
import matplotlib.pyplot as plt

# Crear la figura y los ejes
plt.figure(figsize=(12, 6))

# Graficar los valores reales
plt.plot(y_test_rescaled, label='Valores Reales', linestyle='dashed', color='blue')

# Graficar las predicciones
plt.plot(y_pred_rescaled, label='Predicciones', linestyle='solid', color='red')

# Agregar t√≠tulos y etiquetas
plt.title('Comparaci√≥n entre Predicciones y Valores Reales')
plt.xlabel('√çndice de Tiempo')
plt.ylabel('Ahorro')
plt.legend()
plt.grid(True)

# Mostrar la gr√°fica
plt.show()